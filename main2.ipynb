{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# import pandas and set pandas read_cvs to a variable\n",
    "ufo_data =pd.read_csv('./data/nuforc_reports.csv')\n",
    "# ufo_data.head()\n",
    "df = ufo_data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"start functions to clean data\"\"\"\n",
    "def fill_na(df):\n",
    "    \"\"\"check to see if there are any null values and changes them to NaN\"\"\"\n",
    "    df.fillna(value = \"null\", axis = 1, inplace = True)\n",
    "\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_dupes(dataframe, col_check = None):\n",
    "    \"\"\"drop duplicates among the summaries to ensure the data isnt repeated\"\"\"\n",
    "    df.drop_duplicates(subset=[col_check], inplace = True)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if our data doesnt already have one, this is a function to create an index from a later specified column\n",
    "\"\"\"create the index\"\"\"\n",
    "\n",
    "def add_index(self, col_list, index_name=\"index\"):\n",
    "    df = self.df\n",
    "    \"\"\"create the index by concatting two columns\"\"\"\n",
    "    df[index_name] = df[col_list].apply(lambda row: \"-\".join(row.values.astype(str)), axis=1)\n",
    "    df = df.set_index(index_name, inplace=True)\n",
    "    self.df = df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"write the pandas df back to a csv\"\"\"\n",
    "\n",
    "\n",
    "def write_csv(df):\n",
    "    clean_UFO_data = (f'./data/cleaned_UFO_data.csv')\n",
    "    df.to_csv(clean_UFO_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame({'var_1': ['a', 'b', 'c'], 'var_2': [\n",
    "               1, 2, 3], 'var_3': ['apple', 'banana', 'pear']})\n",
    "cols = ['var_1', 'var_2']    # Set columns to combine\n",
    "df['combined'] = df[cols].apply(\n",
    "    lambda row: ', '.join(row.values.astype(str)), axis=1)\n",
    "\n",
    "# Define which column is index\n",
    "df_i = df.set_index('combined')\n",
    "\n",
    "# Set the index to None\n",
    "df_i.index.names = [None]\n",
    "col_list = [df.city, df.date_time]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {'name': [\"apple\", \"banana\", \"cherry\"], 'quant': [40, 50, 60]})\n",
    "df.columns = ['fruit', 'quantity']\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text, insert, inspect\n",
    "from sqlalchemy import MetaData, Table, Column, Integer, String, Numeric, DateTime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initdb(self, drop_and_replace=False) -> None:\n",
    "    \"\"\"Function to initialize the database with all the tables\"\"\"\n",
    "    \n",
    "     engine = self.engine\n",
    "      metadata = self.metadata\n",
    "       if drop_and_replace:\n",
    "            logger.info(\"\\tDropping existing tables\")\n",
    "            metadata.drop_all()\n",
    "        # Define all our tables\n",
    "        if not inspect(engine).has_table(\"airports\"):\n",
    "            logger.info(\"Creating airports table\")\n",
    "            airport_table = Table(\"airports\",\n",
    "                                  metadata,\n",
    "                                  Column(\"iata\", String(256),\n",
    "                                         primary_key=True),\n",
    "                                  Column(\"airport\", String(256)),\n",
    "                                  Column(\"city\", String(256)),\n",
    "                                  Column(\"state\", String(256)),\n",
    "                   df = DataFrame({'var_1': ['a', 'b', 'c'], 'var_2': [\n",
    "               1, 2, 3], 'var_3': ['apple', 'banana', 'pear']})\n",
    "cols = ['var_1', 'var_2']    # Set columns to combine\n",
    "df['combined'] = df[cols].apply(\n",
    "    lambda row: ', '.join(row.values.astype(str)), axis=1)\n",
    "\n",
    "# Define which column is index\n",
    "df_i = df.set_index('combined')\n",
    "\n",
    "# Set the index to None\n",
    "df_i.index.names = [None]               Column(\"country\", String(256)),\n",
    "                Column(\"lat\", Numeric),\n",
    "                Column(\"lon\", Numeric),\n",
    "                extend_existing=True,\n",
    "            )\n",
    "        else:\n",
    "            logger.info(\"\\tairports table present\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 11 fields in line 878, saw 12\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15911/113521183.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# import pandas and set pandas read_cvs to a variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mufo_filepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./data/complete.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mufo_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mufo_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'date_time'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# df.head()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deb/tests/bigquery_test/venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deb/tests/bigquery_test/venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deb/tests/bigquery_test/venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1055\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deb/tests/bigquery_test/venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2059\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2060\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 11 fields in line 878, saw 12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# import pandas and set pandas read_cvs to a variable\n",
    "ufo_filepath = './data/complete.csv'\n",
    "ufo_data = pd.read_csv(ufo_filepath, index_col = 'date_time')\n",
    "# df.head()\n",
    "\n",
    "\n",
    "#  = ['summary', 'city', 'state', 'date_time',\n",
    "#  'shape', 'duration', 'stats', 'report_link',\n",
    "#  'text', 'posted', 'city_latitude', 'city_longitude']\n",
    "\n",
    "\n",
    "def set_header(df):\n",
    "    header_row = ['datetime', 'city', 'state', 'country', 'shape', \n",
    "                    'duration(seconds)', 'duration(hours/min)', \n",
    "                    'comments', 'date posted', 'latitude', 'longitude'\n",
    "                  ]\n",
    "    df.values[1:] = header_row\n",
    "\n",
    "\n",
    "# datetime, city, state, country, shape, duration(seconds), duration(hours/min), comments, date posted, latitude, longitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_dataframe(filepath: str, index: str) -> None:\n",
    "    \"\"\"\n",
    "    Load a csv file into a pandas dataframe\n",
    "    returns inserted csv into 'df' variable\n",
    "    *args:\n",
    "        filepath: string of filepath to csv file\n",
    "        index: string of column to index dataframe by\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath, header=0, index_col=[index])\n",
    "    return df\n",
    "\n",
    "\n",
    "def index_setter(dataframe, index):\n",
    "    \"\"\"\n",
    "    Sets the index of dataframe to a desired existing column\n",
    "    args*:\n",
    "        dataframe: dataframe to have index changed\n",
    "        index: name of column that index will be set to\n",
    "    \"\"\"\n",
    "    dataframe.set_index(index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import pprint\n",
    "\n",
    "# import pandas and set pandas read_cvs to a variable\n",
    "ufo_filepath = './data/scrubbed.csv'\n",
    "ufo_data = pd.read_csv(ufo_filepath, header = 0)\n",
    "df = ufo_data\n",
    "# helps skip the bad lines to avoid errors\n",
    "# error_bad_lines = False\n",
    "\n",
    "ufo_data.index.values.tolist()\n",
    "\n",
    "# df.set_index(index, inplace = True)\n",
    "# df.head()\n",
    "# for col in ufo_data.columns:\n",
    "    # print(col)\n",
    "# df.fill_na(value = 'null', inplace = True)\n",
    "    \n",
    "# header_row = df.iloc[1]\n",
    "# df = df.values[1:]\n",
    "\n",
    "\n",
    "# col_list = ufo_data.columns.values.tolist()\n",
    "# print(col_list)\n",
    "# # create empty variables so we know what internal variables need to define later\n",
    "# col_list = []\n",
    "# col_check = []\n",
    "\n",
    "\n",
    "# index_list = ['summary', 'city', 'state', 'date_time',\n",
    "#  'shape', 'duration', 'stats', 'report_link',\n",
    "#  'text', 'posted', 'city_latitude', 'city_longitude']\n",
    "# # \"\"\"start functions to clean data\"\"\"\n",
    "\n",
    "df.set_index('datetime', inplace=True)\n",
    "df.head()\n",
    "\n",
    "# \"\"\"if our data doesnt already have one, this is a function to create an index from a later specified column\"\"\"\n",
    "\n",
    "# df2 = df.set_index(index_list, inplace=True)\n",
    "\n",
    "# print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datalab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12104/3667654673.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatalab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatalab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatalab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datalab'"
     ]
    }
   ],
   "source": [
    "from datalab.context import Context\n",
    "import google.datalab.storage as storage\n",
    "import google.datalab.bigquery as bq\n",
    "import pandas as pd\n",
    "\n",
    "# Dataframe to write\n",
    "simple_dataframe = pd.DataFrame(\n",
    "    data=[{1, 2, 3}, {4, 5, 6}], columns=['a', 'b', 'c'])\n",
    "\n",
    "sample_bucket_name = Context.default().project_id + '-datalab-example'\n",
    "sample_bucket_path = 'gs://' + sample_bucket_name\n",
    "sample_bucket_object = sample_bucket_path + '/Hello.txt'\n",
    "bigquery_dataset_name = 'TestDataSet'\n",
    "bigquery_table_name = 'TestTable'\n",
    "\n",
    "# Define storage bucket\n",
    "sample_bucket = storage.Bucket(sample_bucket_name)\n",
    "\n",
    "# Create storage bucket if it does not exist\n",
    "if not sample_bucket.exists():\n",
    "    sample_bucket.create()\n",
    "\n",
    "# Define BigQuery dataset and table\n",
    "dataset = bq.Dataset(bigquery_dataset_name)\n",
    "table = bq.Table(bigquery_dataset_name + '.' + bigquery_table_name)\n",
    "\n",
    "# Create BigQuery dataset\n",
    "if not dataset.exists():\n",
    "    dataset.create()\n",
    "\n",
    "# Create or overwrite the existing table if it exists\n",
    "table_schema = bq.Schema.from_data(simple_dataframe)\n",
    "table.create(schema=table_schema, overwrite=True)\n",
    "\n",
    "# Write the DataFrame to GCS (Google Cloud Storage)\n",
    "\n",
    "\"\"\"Just a note: I believe you need to execute the % %storage commands in a separate cell from the Python code? –\n",
    "dartdog\n",
    "Mar 31, 2016 at 16: 13\n",
    "3\n",
    "It depends on whether you want to execute a line magic or cell magic command. For cell magic it is % % storage, for line magic it is %storage. It's ok to use line magic commands in the same cell as other code. Cell magic commands must be in a separate cell from other code –\n",
    "Anthonios Partheniou\n",
    "Mar 31, 2016 at 16: 43\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"21\n",
    "\n",
    "I spent a lot of time to find the easiest way to solve this:\n",
    "\n",
    "\n",
    "df = pd.DataFrame(...)\n",
    "\n",
    "df.to_csv('gs://bucket/path')\n",
    "Share\n",
    "Improve this answer\n",
    "Follow\n",
    "answered Mar 11, 2020 at 21: 31\n",
    "user avatar\n",
    "Vova Pytsyuk\n",
    "36122 silver badges66 bronze badges\n",
    "1\n",
    "This is hilariously simple. Just make sure to also install gcsfs as a prerequisite(though it'll remind you anyway). If you're coming here in 2020 or later, just skip the complexity and do this. –\n",
    "                                                                                   bsplosion\n",
    "                                                                                   Dec 16, 2021 at 4: 59\n",
    "                                                                                   Is there a way to make a saved file publically accessible directly by passing any argument? –\n",
    "                                                                                   Danish Bansal\n",
    "                                                                                   Jan 28 at 9: 31\n",
    "                                                                                   It is not working. I have created a ubuntu server and installed pip install pandas fsspec gcsfs. I am able to read csv file using pd.read_csv(gs: // BUCKET_PATH) but not able to write –\n",
    "                                                                                   Shiv Krishna Jaiswal\n",
    "                                                                                   Apr 9 at 3: 30\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datalab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12104/354491347.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatalab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatalab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatalab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datalab'"
     ]
    }
   ],
   "source": [
    "from datalab.context import Context\n",
    "import google.datalab.storage as storage\n",
    "import google.datalab.bigquery as bq\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime, city, state, country, shape, duration(seconds), duration(hours/min), comments, date posted, latitude, longitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "with open('./data/complete.csv', 'r') as temp_file:\n",
    "    col_count = [len(l.split(',')) for l in temp_file.readlines()]\n",
    "\n",
    "column_names = [i for i in range(0, max(col_count))]\n",
    "\n",
    "df = pd.read_csv(\"./data/complete.csv\", header=None,\n",
    "                 delimiter=\",\", names=column_names, low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datetime</td>\n",
       "      <td>city</td>\n",
       "      <td>state</td>\n",
       "      <td>country</td>\n",
       "      <td>shape</td>\n",
       "      <td>duration (seconds)</td>\n",
       "      <td>duration (hours/min)</td>\n",
       "      <td>comments</td>\n",
       "      <td>date posted</td>\n",
       "      <td>latitude</td>\n",
       "      <td>longitude</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/10/1949 20:30</td>\n",
       "      <td>san marcos</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>cylinder</td>\n",
       "      <td>2700</td>\n",
       "      <td>45 minutes</td>\n",
       "      <td>\"This event took place in early fall around 19...</td>\n",
       "      <td>4/27/2004</td>\n",
       "      <td>29.8830556</td>\n",
       "      <td>-97.9411111</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/10/1949 21:00</td>\n",
       "      <td>lackland afb</td>\n",
       "      <td>tx</td>\n",
       "      <td></td>\n",
       "      <td>light</td>\n",
       "      <td>7200</td>\n",
       "      <td>1-2 hrs</td>\n",
       "      <td>\"1949 Lackland AFB&amp;#44 TX.  Lights racing acro...</td>\n",
       "      <td>12/16/2005</td>\n",
       "      <td>29.38421</td>\n",
       "      <td>-98.581082</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/10/1955 17:00</td>\n",
       "      <td>chester (uk/england)</td>\n",
       "      <td></td>\n",
       "      <td>gb</td>\n",
       "      <td>circle</td>\n",
       "      <td>20</td>\n",
       "      <td>20 seconds</td>\n",
       "      <td>\"Green/Orange circular disc over Chester&amp;#44 E...</td>\n",
       "      <td>1/21/2008</td>\n",
       "      <td>53.2</td>\n",
       "      <td>-2.916667</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/10/1956 21:00</td>\n",
       "      <td>edna</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>circle</td>\n",
       "      <td>20</td>\n",
       "      <td>1/2 hour</td>\n",
       "      <td>\"My older brother and twin sister were leaving...</td>\n",
       "      <td>1/17/2004</td>\n",
       "      <td>28.9783333</td>\n",
       "      <td>-96.6458333</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88871</th>\n",
       "      <td>9/9/2013 22:00</td>\n",
       "      <td>napa</td>\n",
       "      <td>ca</td>\n",
       "      <td>us</td>\n",
       "      <td>other</td>\n",
       "      <td>1200</td>\n",
       "      <td>hour</td>\n",
       "      <td>\"Napa UFO&amp;#44\"</td>\n",
       "      <td>9/30/2013</td>\n",
       "      <td>38.2972222</td>\n",
       "      <td>-122.2844444</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88872</th>\n",
       "      <td>9/9/2013 22:20</td>\n",
       "      <td>vienna</td>\n",
       "      <td>va</td>\n",
       "      <td>us</td>\n",
       "      <td>circle</td>\n",
       "      <td>5</td>\n",
       "      <td>5 seconds</td>\n",
       "      <td>\"Saw a five gold lit cicular craft moving fast...</td>\n",
       "      <td>9/30/2013</td>\n",
       "      <td>38.9011111</td>\n",
       "      <td>-77.2655556</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88873</th>\n",
       "      <td>9/9/2013 23:00</td>\n",
       "      <td>edmond</td>\n",
       "      <td>ok</td>\n",
       "      <td>us</td>\n",
       "      <td>cigar</td>\n",
       "      <td>1020</td>\n",
       "      <td>17 minutes</td>\n",
       "      <td>\"2 witnesses 2  miles apart&amp;#44 Red &amp;amp; Whit...</td>\n",
       "      <td>9/30/2013</td>\n",
       "      <td>35.6527778</td>\n",
       "      <td>-97.4777778</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88874</th>\n",
       "      <td>9/9/2013 23:00</td>\n",
       "      <td>starr</td>\n",
       "      <td>sc</td>\n",
       "      <td>us</td>\n",
       "      <td>diamond</td>\n",
       "      <td>0</td>\n",
       "      <td>2 nights</td>\n",
       "      <td>\"On September ninth my wife and i noticed stra...</td>\n",
       "      <td>9/30/2013</td>\n",
       "      <td>34.3769444</td>\n",
       "      <td>-82.6958333</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88875</th>\n",
       "      <td>9/9/2013 23:30</td>\n",
       "      <td>ft. lauderdale</td>\n",
       "      <td>fl</td>\n",
       "      <td>us</td>\n",
       "      <td>oval</td>\n",
       "      <td>0</td>\n",
       "      <td>still occuring</td>\n",
       "      <td>\"Hovering object lit with red and white lights...</td>\n",
       "      <td>9/30/2013</td>\n",
       "      <td>26.1219444</td>\n",
       "      <td>-80.1436111</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88876 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0                     1      2        3         4   \\\n",
       "0              datetime                  city  state  country     shape   \n",
       "1      10/10/1949 20:30            san marcos     tx       us  cylinder   \n",
       "2      10/10/1949 21:00          lackland afb     tx              light   \n",
       "3      10/10/1955 17:00  chester (uk/england)              gb    circle   \n",
       "4      10/10/1956 21:00                  edna     tx       us    circle   \n",
       "...                 ...                   ...    ...      ...       ...   \n",
       "88871    9/9/2013 22:00                  napa     ca       us     other   \n",
       "88872    9/9/2013 22:20                vienna     va       us    circle   \n",
       "88873    9/9/2013 23:00                edmond     ok       us     cigar   \n",
       "88874    9/9/2013 23:00                 starr     sc       us   diamond   \n",
       "88875    9/9/2013 23:30        ft. lauderdale     fl       us      oval   \n",
       "\n",
       "                       5                     6   \\\n",
       "0      duration (seconds)  duration (hours/min)   \n",
       "1                    2700            45 minutes   \n",
       "2                    7200               1-2 hrs   \n",
       "3                      20            20 seconds   \n",
       "4                      20              1/2 hour   \n",
       "...                   ...                   ...   \n",
       "88871                1200                  hour   \n",
       "88872                   5             5 seconds   \n",
       "88873                1020            17 minutes   \n",
       "88874                   0              2 nights   \n",
       "88875                   0        still occuring   \n",
       "\n",
       "                                                      7            8   \\\n",
       "0                                               comments  date posted   \n",
       "1      \"This event took place in early fall around 19...    4/27/2004   \n",
       "2      \"1949 Lackland AFB&#44 TX.  Lights racing acro...   12/16/2005   \n",
       "3      \"Green/Orange circular disc over Chester&#44 E...    1/21/2008   \n",
       "4      \"My older brother and twin sister were leaving...    1/17/2004   \n",
       "...                                                  ...          ...   \n",
       "88871                                     \"Napa UFO&#44\"    9/30/2013   \n",
       "88872  \"Saw a five gold lit cicular craft moving fast...    9/30/2013   \n",
       "88873  \"2 witnesses 2  miles apart&#44 Red &amp; Whit...    9/30/2013   \n",
       "88874  \"On September ninth my wife and i noticed stra...    9/30/2013   \n",
       "88875  \"Hovering object lit with red and white lights...    9/30/2013   \n",
       "\n",
       "               9             10    11  \n",
       "0        latitude     longitude  None  \n",
       "1      29.8830556   -97.9411111  None  \n",
       "2        29.38421    -98.581082  None  \n",
       "3            53.2     -2.916667  None  \n",
       "4      28.9783333   -96.6458333  None  \n",
       "...           ...           ...   ...  \n",
       "88871  38.2972222  -122.2844444  None  \n",
       "88872  38.9011111   -77.2655556  None  \n",
       "88873  35.6527778   -97.4777778  None  \n",
       "88874  34.3769444   -82.6958333  None  \n",
       "88875  26.1219444   -80.1436111  None  \n",
       "\n",
       "[88876 rows x 12 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Make a one column DataFrame with each row being a line in the .csv file\n",
    "Split each row on commas and expand the DataFrame\n",
    "\"\"\"\n",
    "# \n",
    "\n",
    "df = pd.read_fwf('./data/complete.csv', header=None)\n",
    "df[0].str.split(',', expand=True)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e1e9d3213e041034ab2a4b732cb36456a1e7a64065615552b23d589624cd542"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
